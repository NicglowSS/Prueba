{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOxcuizs77RIXy2PksEozya"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L_Zg2IxMAiPk","outputId":"7d54d9e1-3de5-4d9d-831a-2c55ec53955f","executionInfo":{"status":"ok","timestamp":1701211991726,"user_tz":360,"elapsed":7127,"user":{"displayName":"Hern치ndez Guerrero Leonardo David","userId":"17737298581546128851"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: comet_ml in /usr/local/lib/python3.10/dist-packages (3.35.3)\n","Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (4.19.2)\n","Requirement already satisfied: psutil>=5.6.3 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (5.9.5)\n","Requirement already satisfied: python-box<7.0.0 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (6.1.0)\n","Requirement already satisfied: requests-toolbelt>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (1.0.0)\n","Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (2.31.0)\n","Requirement already satisfied: semantic-version>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (2.10.0)\n","Requirement already satisfied: sentry-sdk>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (1.37.1)\n","Requirement already satisfied: simplejson in /usr/local/lib/python3.10/dist-packages (from comet_ml) (3.19.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from comet_ml) (1.16.0)\n","Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (2.0.7)\n","Requirement already satisfied: websocket-client<1.4.0,>=0.55.0 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (1.3.3)\n","Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (1.14.1)\n","Requirement already satisfied: wurlitzer>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (3.0.3)\n","Requirement already satisfied: everett[ini]<3.2.0,>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (3.1.0)\n","Requirement already satisfied: dulwich!=0.20.33,>=0.20.6 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (0.21.6)\n","Requirement already satisfied: rich>=13.3.2 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (13.7.0)\n","Requirement already satisfied: configobj in /usr/local/lib/python3.10/dist-packages (from everett[ini]<3.2.0,>=1.0.1->comet_ml) (5.0.8)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (23.1.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (2023.11.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (0.31.0)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (0.13.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet_ml) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet_ml) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet_ml) (2023.7.22)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.3.2->comet_ml) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.3.2->comet_ml) (2.16.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=13.3.2->comet_ml) (0.1.2)\n"]}],"source":["%pip install comet_ml #libreria a instalar"]},{"cell_type":"code","source":["import comet_ml\n","comet_ml.init(project_name=\"RNA_Densa_M2\") #nombre a dar al experimento"],"metadata":{"id":"g6hZpUiPAtrC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Imports\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.datasets import mnist #base de datos\n","from tensorflow.keras.models import Sequential # checar cada uno de los que faltan\n","from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input\n","from tensorflow.keras.optimizers import RMSprop, SGD\n","from tensorflow.keras import regularizers\n","from keras.callbacks import ModelCheckpoint # sirve para dar respuesta del proceso de entrenamiento de la red"],"metadata":{"id":"czgl5_6tA7Pe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["experiment = comet_ml.Experiment(  # para activar las Graficas en comet\n","    auto_histogram_weight_logging=True,\n","    auto_histogram_gradient_logging=True,\n","    auto_histogram_activation_logging=True,\n","    log_code=True, # para subir el codigo a comet para no perder el progreso\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j__tspO4BGYR","outputId":"435129f4-c790-400c-de6a-633621eb6c0c","executionInfo":{"status":"ok","timestamp":1701212033329,"user_tz":360,"elapsed":2911,"user":{"displayName":"Hern치ndez Guerrero Leonardo David","userId":"17737298581546128851"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/nicglowss/rna-densa-m2/89cab9133f194c1ca9342db7397f32a9\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 2\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n","\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/content' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/nicglowss/rna-densa-m2/5d7108c24a7b4372b270a828d97cff81\n","\n"]}]},{"cell_type":"code","source":["# pre-procesamiento\n","dataset=mnist.load_data()# en el dataset se guardan todas las imagenes del mnist con sus etiquetas\n","(x_train, y_train), (x_test, y_test) = dataset\n","\n","# se van a guardar en el forato de binario\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","\n","# =numero de pixeles normalizando el no. de pixeles\n","x_train /= 255  # x_trainv = x_trainv/255\n","x_test /= 255\n","\n","#clasificacion de clases\n","num_classes=10\n","y_trainc = keras.utils.to_categorical(y_train, num_classes) #analiza los datos y los acomoda en las distintas clases\n","y_testc = keras.utils.to_categorical(y_test, num_classes)"],"metadata":{"id":"qJNeAdHbBUM-","executionInfo":{"status":"ok","timestamp":1701212036938,"user_tz":360,"elapsed":506,"user":{"displayName":"Hern치ndez Guerrero Leonardo David","userId":"17737298581546128851"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7b420917-c231-4b28-c94f-a17ac982243d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"code","source":["# Parametros\n","parameters = {\n","    \"batch_size\": 10,\n","    \"epochs\": 100, # Variamos las epocas de 30/10/50/100\n","    \"optimizer\": \"SGD\",\n","    \"loss\": \"categorical_crossentropy\",\n","}\n","\n","experiment.log_parameters(parameters) # diccionario subido a comet"],"metadata":{"id":"zbiaW1VkBHH6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Arquitetura de la red\n","model = Sequential()\n","# aqui empezamos\n","model.add(Input(shape=(28,28))) #Flaten no tiene la opcion input_shape por lo tanto se tiene que agregar esta capa\n","                                #28x28 es el tama침o de la imagen\n","model.add(Flatten()) #Otra forma de aplanar las imagenes, las forma en una linea\n","model.add(Dense(784, activation='sigmoid')) # esta es la capa densa de no neuronas de forma vertical (en este caso agarramos el total de pixeles)\n","                                            # su funcion de activacion es la sigmoide (respuesta de la neurona de 0 a 1)\n","                                            # Estas dos son las principales\n","\n","model.add(Dense(10, activation='softmax'))  # son las de salida literal porque estan al final\n","\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GUl8whP1BOdy","outputId":"7c29f7ee-f229-42c1-e709-1080b1aaa1b0","executionInfo":{"status":"ok","timestamp":1701212090592,"user_tz":360,"elapsed":243,"user":{"displayName":"Hern치ndez Guerrero Leonardo David","userId":"17737298581546128851"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten (Flatten)           (None, 784)               0         \n","                                                                 \n"," dense (Dense)               (None, 784)               615440    \n","                                                                 \n"," dense_1 (Dense)             (None, 10)                7850      \n","                                                                 \n","=================================================================\n","Total params: 623290 (2.38 MB)\n","Trainable params: 623290 (2.38 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# specify the path where you want to save the model\n","filepath = \"mejor-modelo1.1.hdf5\"\n","\n","# initialize the ModelCheckpoint callback\n","checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')"],"metadata":{"id":"yickXqeNHaGo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Inicia el entrenamiento de la red\n","model.compile(loss=parameters['loss'],optimizer=SGD(learning_rate=0.1,ema_momentum=0.9),metrics=['accuracy'])\n","model.fit(x_train, y_trainc,\n","                    batch_size=parameters['batch_size'],\n","                    epochs=parameters[\"epochs\"],\n","                    verbose=1,\n","                    validation_data=(x_test, y_testc),\n","                    callbacks=[checkpoint])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RipmZnRwEznJ","outputId":"45748c18-3282-4f8f-f7f6-ea8e136f3f7e","executionInfo":{"status":"ok","timestamp":1701214120669,"user_tz":360,"elapsed":2003131,"user":{"displayName":"Hern치ndez Guerrero Leonardo David","userId":"17737298581546128851"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[1;38;5;39mCOMET INFO:\u001b[0m Ignoring automatic log_parameter('verbose') because 'keras:verbose' is in COMET_LOGGING_PARAMETERS_IGNORE\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","5991/6000 [============================>.] - ETA: 0s - loss: 0.4341 - accuracy: 0.8722\n","Epoch 1: val_loss improved from inf to 0.26684, saving model to mejor-modelo1.1.hdf5\n","6000/6000 [==============================] - 18s 3ms/step - loss: 0.4337 - accuracy: 0.8723 - val_loss: 0.2668 - val_accuracy: 0.9227\n","Epoch 2/100\n","  18/6000 [..............................] - ETA: 17s - loss: 0.2500 - accuracy: 0.9333"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["5995/6000 [============================>.] - ETA: 0s - loss: 0.2459 - accuracy: 0.9282\n","Epoch 2: val_loss improved from 0.26684 to 0.21299, saving model to mejor-modelo1.1.hdf5\n","6000/6000 [==============================] - 19s 3ms/step - loss: 0.2460 - accuracy: 0.9282 - val_loss: 0.2130 - val_accuracy: 0.9371\n","Epoch 3/100\n","5999/6000 [============================>.] - ETA: 0s - loss: 0.1813 - accuracy: 0.9479\n","Epoch 3: val_loss improved from 0.21299 to 0.16231, saving model to mejor-modelo1.1.hdf5\n","6000/6000 [==============================] - 20s 3ms/step - loss: 0.1812 - accuracy: 0.9479 - val_loss: 0.1623 - val_accuracy: 0.9508\n","Epoch 4/100\n","5985/6000 [============================>.] - ETA: 0s - loss: 0.1434 - accuracy: 0.9580\n","Epoch 4: val_loss improved from 0.16231 to 0.12810, saving model to mejor-modelo1.1.hdf5\n","6000/6000 [==============================] - 18s 3ms/step - loss: 0.1435 - accuracy: 0.9580 - val_loss: 0.1281 - val_accuracy: 0.9617\n","Epoch 5/100\n","5992/6000 [============================>.] - ETA: 0s - loss: 0.1180 - accuracy: 0.9660\n","Epoch 5: val_loss improved from 0.12810 to 0.11122, saving model to mejor-modelo1.1.hdf5\n","6000/6000 [==============================] - 20s 3ms/step - loss: 0.1179 - accuracy: 0.9660 - val_loss: 0.1112 - val_accuracy: 0.9662\n","Epoch 6/100\n","5994/6000 [============================>.] - ETA: 0s - loss: 0.0992 - accuracy: 0.9712\n","Epoch 6: val_loss improved from 0.11122 to 0.09902, saving model to mejor-modelo1.1.hdf5\n","6000/6000 [==============================] - 17s 3ms/step - loss: 0.0992 - accuracy: 0.9712 - val_loss: 0.0990 - val_accuracy: 0.9698\n","Epoch 7/100\n","5988/6000 [============================>.] - ETA: 0s - loss: 0.0852 - accuracy: 0.9750\n","Epoch 7: val_loss improved from 0.09902 to 0.09412, saving model to mejor-modelo1.1.hdf5\n","6000/6000 [==============================] - 17s 3ms/step - loss: 0.0852 - accuracy: 0.9750 - val_loss: 0.0941 - val_accuracy: 0.9714\n","Epoch 8/100\n","5989/6000 [============================>.] - ETA: 0s - loss: 0.0741 - accuracy: 0.9783\n","Epoch 8: val_loss improved from 0.09412 to 0.08746, saving model to mejor-modelo1.1.hdf5\n","6000/6000 [==============================] - 20s 3ms/step - loss: 0.0740 - accuracy: 0.9783 - val_loss: 0.0875 - val_accuracy: 0.9730\n","Epoch 9/100\n","5999/6000 [============================>.] - ETA: 0s - loss: 0.0655 - accuracy: 0.9806\n","Epoch 9: val_loss improved from 0.08746 to 0.08401, saving model to mejor-modelo1.1.hdf5\n","6000/6000 [==============================] - 21s 4ms/step - loss: 0.0655 - accuracy: 0.9806 - val_loss: 0.0840 - val_accuracy: 0.9739\n","Epoch 10/100\n","6000/6000 [==============================] - ETA: 0s - loss: 0.0582 - accuracy: 0.9827\n","Epoch 10: val_loss improved from 0.08401 to 0.08005, saving model to mejor-modelo1.1.hdf5\n","6000/6000 [==============================] - 21s 3ms/step - loss: 0.0582 - accuracy: 0.9827 - val_loss: 0.0800 - val_accuracy: 0.9744\n","Epoch 11/100\n","5996/6000 [============================>.] - ETA: 0s - loss: 0.0514 - accuracy: 0.9854\n","Epoch 11: val_loss improved from 0.08005 to 0.07835, saving model to mejor-modelo1.1.hdf5\n","6000/6000 [==============================] - 20s 3ms/step - loss: 0.0514 - accuracy: 0.9854 - val_loss: 0.0784 - val_accuracy: 0.9752\n","Epoch 12/100\n","5986/6000 [============================>.] - ETA: 0s - loss: 0.0458 - accuracy: 0.9865\n","Epoch 12: val_loss improved from 0.07835 to 0.07361, saving model to mejor-modelo1.1.hdf5\n","6000/6000 [==============================] - 17s 3ms/step - loss: 0.0459 - accuracy: 0.9865 - val_loss: 0.0736 - val_accuracy: 0.9766\n","Epoch 13/100\n","5985/6000 [============================>.] - ETA: 0s - loss: 0.0414 - accuracy: 0.9885\n","Epoch 13: val_loss improved from 0.07361 to 0.07254, saving model to mejor-modelo1.1.hdf5\n","6000/6000 [==============================] - 18s 3ms/step - loss: 0.0414 - accuracy: 0.9885 - val_loss: 0.0725 - val_accuracy: 0.9779\n","Epoch 14/100\n","5994/6000 [============================>.] - ETA: 0s - loss: 0.0372 - accuracy: 0.9899\n","Epoch 14: val_loss did not improve from 0.07254\n","6000/6000 [==============================] - 20s 3ms/step - loss: 0.0372 - accuracy: 0.9900 - val_loss: 0.0736 - val_accuracy: 0.9774\n","Epoch 15/100\n","6000/6000 [==============================] - ETA: 0s - loss: 0.0333 - accuracy: 0.9909\n","Epoch 15: val_loss improved from 0.07254 to 0.06965, saving model to mejor-modelo1.1.hdf5\n","6000/6000 [==============================] - 20s 3ms/step - loss: 0.0333 - accuracy: 0.9909 - val_loss: 0.0697 - val_accuracy: 0.9784\n","Epoch 16/100\n","5984/6000 [============================>.] - ETA: 0s - loss: 0.0304 - accuracy: 0.9921\n","Epoch 16: val_loss improved from 0.06965 to 0.06589, saving model to mejor-modelo1.1.hdf5\n","6000/6000 [==============================] - 17s 3ms/step - loss: 0.0303 - accuracy: 0.9922 - val_loss: 0.0659 - val_accuracy: 0.9796\n","Epoch 17/100\n","5997/6000 [============================>.] - ETA: 0s - loss: 0.0273 - accuracy: 0.9930\n","Epoch 17: val_loss did not improve from 0.06589\n","6000/6000 [==============================] - 17s 3ms/step - loss: 0.0273 - accuracy: 0.9930 - val_loss: 0.0671 - val_accuracy: 0.9795\n","Epoch 18/100\n","5992/6000 [============================>.] - ETA: 0s - loss: 0.0247 - accuracy: 0.9942\n","Epoch 18: val_loss improved from 0.06589 to 0.06453, saving model to mejor-modelo1.1.hdf5\n","6000/6000 [==============================] - 17s 3ms/step - loss: 0.0247 - accuracy: 0.9942 - val_loss: 0.0645 - val_accuracy: 0.9802\n","Epoch 19/100\n","5995/6000 [============================>.] - ETA: 0s - loss: 0.0227 - accuracy: 0.9948\n","Epoch 19: val_loss improved from 0.06453 to 0.06440, saving model to mejor-modelo1.1.hdf5\n","6000/6000 [==============================] - 21s 4ms/step - loss: 0.0227 - accuracy: 0.9948 - val_loss: 0.0644 - val_accuracy: 0.9789\n","Epoch 20/100\n","5994/6000 [============================>.] - ETA: 0s - loss: 0.0202 - accuracy: 0.9959\n","Epoch 20: val_loss did not improve from 0.06440\n","6000/6000 [==============================] - 21s 3ms/step - loss: 0.0202 - accuracy: 0.9959 - val_loss: 0.0648 - val_accuracy: 0.9800\n","Epoch 21/100\n","5989/6000 [============================>.] - ETA: 0s - loss: 0.0187 - accuracy: 0.9963\n","Epoch 21: val_loss improved from 0.06440 to 0.06269, saving model to mejor-modelo1.1.hdf5\n","6000/6000 [==============================] - 22s 4ms/step - loss: 0.0187 - accuracy: 0.9963 - val_loss: 0.0627 - val_accuracy: 0.9808\n","Epoch 22/100\n","5991/6000 [============================>.] - ETA: 0s - loss: 0.0169 - accuracy: 0.9969\n","Epoch 22: val_loss improved from 0.06269 to 0.06232, saving model to mejor-modelo1.1.hdf5\n","6000/6000 [==============================] - 22s 4ms/step - loss: 0.0169 - accuracy: 0.9969 - val_loss: 0.0623 - val_accuracy: 0.9813\n","Epoch 23/100\n","5984/6000 [============================>.] - ETA: 0s - loss: 0.0154 - accuracy: 0.9972\n","Epoch 23: val_loss did not improve from 0.06232\n","6000/6000 [==============================] - 21s 3ms/step - loss: 0.0154 - accuracy: 0.9972 - val_loss: 0.0639 - val_accuracy: 0.9806\n","Epoch 24/100\n","5986/6000 [============================>.] - ETA: 0s - loss: 0.0140 - accuracy: 0.9978\n","Epoch 24: val_loss improved from 0.06232 to 0.06202, saving model to mejor-modelo1.1.hdf5\n","6000/6000 [==============================] - 21s 4ms/step - loss: 0.0139 - accuracy: 0.9979 - val_loss: 0.0620 - val_accuracy: 0.9809\n","Epoch 25/100\n","5993/6000 [============================>.] - ETA: 0s - loss: 0.0131 - accuracy: 0.9979\n","Epoch 25: val_loss did not improve from 0.06202\n","6000/6000 [==============================] - 22s 4ms/step - loss: 0.0132 - accuracy: 0.9979 - val_loss: 0.0626 - val_accuracy: 0.9817\n","Epoch 26/100\n","5990/6000 [============================>.] - ETA: 0s - loss: 0.0120 - accuracy: 0.9982\n","Epoch 26: val_loss improved from 0.06202 to 0.06172, saving model to mejor-modelo1.1.hdf5\n","6000/6000 [==============================] - 22s 4ms/step - loss: 0.0120 - accuracy: 0.9982 - val_loss: 0.0617 - val_accuracy: 0.9819\n","Epoch 27/100\n","5988/6000 [============================>.] - ETA: 0s - loss: 0.0108 - accuracy: 0.9987\n","Epoch 27: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 22s 4ms/step - loss: 0.0108 - accuracy: 0.9987 - val_loss: 0.0660 - val_accuracy: 0.9808\n","Epoch 28/100\n","5982/6000 [============================>.] - ETA: 0s - loss: 0.0103 - accuracy: 0.9988\n","Epoch 28: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 19s 3ms/step - loss: 0.0103 - accuracy: 0.9988 - val_loss: 0.0622 - val_accuracy: 0.9814\n","Epoch 29/100\n","5982/6000 [============================>.] - ETA: 0s - loss: 0.0094 - accuracy: 0.9990\n","Epoch 29: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 18s 3ms/step - loss: 0.0094 - accuracy: 0.9990 - val_loss: 0.0625 - val_accuracy: 0.9814\n","Epoch 30/100\n","5996/6000 [============================>.] - ETA: 0s - loss: 0.0087 - accuracy: 0.9992\n","Epoch 30: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 17s 3ms/step - loss: 0.0087 - accuracy: 0.9992 - val_loss: 0.0640 - val_accuracy: 0.9803\n","Epoch 31/100\n","5992/6000 [============================>.] - ETA: 0s - loss: 0.0081 - accuracy: 0.9992\n","Epoch 31: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 20s 3ms/step - loss: 0.0080 - accuracy: 0.9992 - val_loss: 0.0630 - val_accuracy: 0.9803\n","Epoch 32/100\n","5986/6000 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.9994\n","Epoch 32: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 21s 4ms/step - loss: 0.0075 - accuracy: 0.9994 - val_loss: 0.0631 - val_accuracy: 0.9812\n","Epoch 33/100\n","5997/6000 [============================>.] - ETA: 0s - loss: 0.0069 - accuracy: 0.9995\n","Epoch 33: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 20s 3ms/step - loss: 0.0069 - accuracy: 0.9995 - val_loss: 0.0667 - val_accuracy: 0.9806\n","Epoch 34/100\n","5995/6000 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9996\n","Epoch 34: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 21s 3ms/step - loss: 0.0065 - accuracy: 0.9996 - val_loss: 0.0648 - val_accuracy: 0.9811\n","Epoch 35/100\n","5984/6000 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9996\n","Epoch 35: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 21s 3ms/step - loss: 0.0061 - accuracy: 0.9997 - val_loss: 0.0636 - val_accuracy: 0.9813\n","Epoch 36/100\n","6000/6000 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9997\n","Epoch 36: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 21s 3ms/step - loss: 0.0057 - accuracy: 0.9997 - val_loss: 0.0637 - val_accuracy: 0.9815\n","Epoch 37/100\n","5992/6000 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9997\n","Epoch 37: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 19s 3ms/step - loss: 0.0053 - accuracy: 0.9997 - val_loss: 0.0644 - val_accuracy: 0.9809\n","Epoch 38/100\n","5999/6000 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9997\n","Epoch 38: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 18s 3ms/step - loss: 0.0051 - accuracy: 0.9997 - val_loss: 0.0644 - val_accuracy: 0.9809\n","Epoch 39/100\n","5993/6000 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9997\n","Epoch 39: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 21s 4ms/step - loss: 0.0048 - accuracy: 0.9997 - val_loss: 0.0645 - val_accuracy: 0.9816\n","Epoch 40/100\n","5996/6000 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.9998\n","Epoch 40: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 20s 3ms/step - loss: 0.0046 - accuracy: 0.9998 - val_loss: 0.0646 - val_accuracy: 0.9808\n","Epoch 41/100\n","5981/6000 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.9998\n","Epoch 41: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 19s 3ms/step - loss: 0.0043 - accuracy: 0.9998 - val_loss: 0.0651 - val_accuracy: 0.9807\n","Epoch 42/100\n","5987/6000 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9999\n","Epoch 42: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 17s 3ms/step - loss: 0.0041 - accuracy: 0.9999 - val_loss: 0.0644 - val_accuracy: 0.9823\n","Epoch 43/100\n","5989/6000 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9999\n","Epoch 43: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 16s 3ms/step - loss: 0.0039 - accuracy: 0.9999 - val_loss: 0.0657 - val_accuracy: 0.9812\n","Epoch 44/100\n","5981/6000 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9999\n","Epoch 44: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 17s 3ms/step - loss: 0.0037 - accuracy: 0.9999 - val_loss: 0.0659 - val_accuracy: 0.9810\n","Epoch 45/100\n","5991/6000 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9999\n","Epoch 45: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 16s 3ms/step - loss: 0.0036 - accuracy: 0.9999 - val_loss: 0.0646 - val_accuracy: 0.9813\n","Epoch 46/100\n","5991/6000 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9999\n","Epoch 46: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 16s 3ms/step - loss: 0.0034 - accuracy: 0.9999 - val_loss: 0.0653 - val_accuracy: 0.9812\n","Epoch 47/100\n","5989/6000 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9999\n","Epoch 47: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 16s 3ms/step - loss: 0.0032 - accuracy: 0.9999 - val_loss: 0.0655 - val_accuracy: 0.9813\n","Epoch 48/100\n","5999/6000 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 1.0000\n","Epoch 48: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 16s 3ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0648 - val_accuracy: 0.9817\n","Epoch 49/100\n","5986/6000 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9999\n","Epoch 49: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 16s 3ms/step - loss: 0.0030 - accuracy: 0.9999 - val_loss: 0.0651 - val_accuracy: 0.9813\n","Epoch 50/100\n","5986/6000 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 1.0000\n","Epoch 50: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 16s 3ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0656 - val_accuracy: 0.9816\n","Epoch 51/100\n","5999/6000 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 1.0000\n","Epoch 51: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 17s 3ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0660 - val_accuracy: 0.9812\n","Epoch 52/100\n","5997/6000 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 1.0000\n","Epoch 52: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 16s 3ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0659 - val_accuracy: 0.9815\n","Epoch 53/100\n","5986/6000 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 1.0000\n","Epoch 53: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 16s 3ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0657 - val_accuracy: 0.9814\n","Epoch 54/100\n","5993/6000 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 1.0000\n","Epoch 54: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 17s 3ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0662 - val_accuracy: 0.9819\n","Epoch 55/100\n","5994/6000 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 1.0000\n","Epoch 55: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 16s 3ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0656 - val_accuracy: 0.9815\n","Epoch 56/100\n","5995/6000 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000\n","Epoch 56: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 16s 3ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0657 - val_accuracy: 0.9817\n","Epoch 57/100\n","5999/6000 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000\n","Epoch 57: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 17s 3ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0664 - val_accuracy: 0.9818\n","Epoch 58/100\n","6000/6000 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000\n","Epoch 58: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 24s 4ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0666 - val_accuracy: 0.9818\n","Epoch 59/100\n","5999/6000 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 1.0000\n","Epoch 59: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 22s 4ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0664 - val_accuracy: 0.9822\n","Epoch 60/100\n","5997/6000 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 1.0000\n","Epoch 60: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 22s 4ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0665 - val_accuracy: 0.9817\n","Epoch 61/100\n","5993/6000 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 1.0000\n","Epoch 61: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 23s 4ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0664 - val_accuracy: 0.9821\n","Epoch 62/100\n","5984/6000 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 1.0000\n","Epoch 62: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 21s 3ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0664 - val_accuracy: 0.9821\n","Epoch 63/100\n","5992/6000 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000\n","Epoch 63: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 22s 4ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0674 - val_accuracy: 0.9819\n","Epoch 64/100\n","5992/6000 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000\n","Epoch 64: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 22s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0671 - val_accuracy: 0.9818\n","Epoch 65/100\n","5992/6000 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000\n","Epoch 65: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 22s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0675 - val_accuracy: 0.9819\n","Epoch 66/100\n","5991/6000 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000\n","Epoch 66: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 21s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0678 - val_accuracy: 0.9815\n","Epoch 67/100\n","5986/6000 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000\n","Epoch 67: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 22s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0677 - val_accuracy: 0.9818\n","Epoch 68/100\n","5999/6000 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000\n","Epoch 68: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 20s 3ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0680 - val_accuracy: 0.9817\n","Epoch 69/100\n","6000/6000 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000\n","Epoch 69: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 20s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0676 - val_accuracy: 0.9815\n","Epoch 70/100\n","5990/6000 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000\n","Epoch 70: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 21s 4ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0675 - val_accuracy: 0.9817\n","Epoch 71/100\n","5991/6000 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000\n","Epoch 71: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 21s 4ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0676 - val_accuracy: 0.9817\n","Epoch 72/100\n","5997/6000 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n","Epoch 72: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 21s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0678 - val_accuracy: 0.9812\n","Epoch 73/100\n","5991/6000 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n","Epoch 73: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 20s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0681 - val_accuracy: 0.9812\n","Epoch 74/100\n","5982/6000 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000\n","Epoch 74: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 22s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0676 - val_accuracy: 0.9816\n","Epoch 75/100\n","5996/6000 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000\n","Epoch 75: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 22s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0685 - val_accuracy: 0.9816\n","Epoch 76/100\n","5989/6000 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000\n","Epoch 76: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 21s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0684 - val_accuracy: 0.9817\n","Epoch 77/100\n","5994/6000 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000\n","Epoch 77: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 21s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0684 - val_accuracy: 0.9816\n","Epoch 78/100\n","5994/6000 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n","Epoch 78: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 20s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0684 - val_accuracy: 0.9814\n","Epoch 79/100\n","5996/6000 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n","Epoch 79: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 21s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0683 - val_accuracy: 0.9818\n","Epoch 80/100\n","5991/6000 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n","Epoch 80: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 21s 4ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0687 - val_accuracy: 0.9820\n","Epoch 81/100\n","5989/6000 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n","Epoch 81: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 21s 4ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0689 - val_accuracy: 0.9816\n","Epoch 82/100\n","5998/6000 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n","Epoch 82: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 21s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0688 - val_accuracy: 0.9818\n","Epoch 83/100\n","5998/6000 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n","Epoch 83: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 22s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0686 - val_accuracy: 0.9818\n","Epoch 84/100\n","5994/6000 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n","Epoch 84: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 21s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0690 - val_accuracy: 0.9818\n","Epoch 85/100\n","5996/6000 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n","Epoch 85: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 20s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0694 - val_accuracy: 0.9817\n","Epoch 86/100\n","5991/6000 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n","Epoch 86: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 22s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0694 - val_accuracy: 0.9816\n","Epoch 87/100\n","5996/6000 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n","Epoch 87: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 22s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0695 - val_accuracy: 0.9819\n","Epoch 88/100\n","5984/6000 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n","Epoch 88: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 23s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0692 - val_accuracy: 0.9816\n","Epoch 89/100\n","5994/6000 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n","Epoch 89: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 22s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0696 - val_accuracy: 0.9817\n","Epoch 90/100\n","5991/6000 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n","Epoch 90: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 22s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0698 - val_accuracy: 0.9816\n","Epoch 91/100\n","5994/6000 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n","Epoch 91: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 20s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0699 - val_accuracy: 0.9815\n","Epoch 92/100\n","5999/6000 [============================>.] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000\n","Epoch 92: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 21s 4ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0697 - val_accuracy: 0.9815\n","Epoch 93/100\n","5999/6000 [============================>.] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000\n","Epoch 93: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 18s 3ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0696 - val_accuracy: 0.9816\n","Epoch 94/100\n","5991/6000 [============================>.] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000\n","Epoch 94: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 18s 3ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0702 - val_accuracy: 0.9816\n","Epoch 95/100\n","5985/6000 [============================>.] - ETA: 0s - loss: 9.8492e-04 - accuracy: 1.0000\n","Epoch 95: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 17s 3ms/step - loss: 9.8748e-04 - accuracy: 1.0000 - val_loss: 0.0697 - val_accuracy: 0.9816\n","Epoch 96/100\n","5990/6000 [============================>.] - ETA: 0s - loss: 9.6900e-04 - accuracy: 1.0000\n","Epoch 96: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 18s 3ms/step - loss: 9.7102e-04 - accuracy: 1.0000 - val_loss: 0.0701 - val_accuracy: 0.9817\n","Epoch 97/100\n","5985/6000 [============================>.] - ETA: 0s - loss: 9.5545e-04 - accuracy: 1.0000\n","Epoch 97: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 22s 4ms/step - loss: 9.5655e-04 - accuracy: 1.0000 - val_loss: 0.0704 - val_accuracy: 0.9818\n","Epoch 98/100\n","5989/6000 [============================>.] - ETA: 0s - loss: 9.4286e-04 - accuracy: 1.0000\n","Epoch 98: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 22s 4ms/step - loss: 9.4272e-04 - accuracy: 1.0000 - val_loss: 0.0705 - val_accuracy: 0.9816\n","Epoch 99/100\n","5995/6000 [============================>.] - ETA: 0s - loss: 9.3208e-04 - accuracy: 1.0000\n","Epoch 99: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 22s 4ms/step - loss: 9.3174e-04 - accuracy: 1.0000 - val_loss: 0.0702 - val_accuracy: 0.9819\n","Epoch 100/100\n","5994/6000 [============================>.] - ETA: 0s - loss: 9.1642e-04 - accuracy: 1.0000\n","Epoch 100: val_loss did not improve from 0.06172\n","6000/6000 [==============================] - 20s 3ms/step - loss: 9.1615e-04 - accuracy: 1.0000 - val_loss: 0.0703 - val_accuracy: 0.9819\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7d36948e8b20>"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["experiment.log_model(\"MNIST1\", \"mejor-modelo1.1.hdf5\")"],"metadata":{"id":"-onR7D9SK9FN","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7d4e5196-153f-40a8-c8cd-36eac9692f06","executionInfo":{"status":"ok","timestamp":1701214730481,"user_tz":360,"elapsed":175,"user":{"displayName":"Hern치ndez Guerrero Leonardo David","userId":"17737298581546128851"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'web': 'https://www.comet.com/api/asset/download?assetId=cd794acf0fc0450abd9de7381f129e7d&experimentKey=5d7108c24a7b4372b270a828d97cff81',\n"," 'api': 'https://www.comet.com/api/rest/v2/experiment/asset/get-asset?assetId=cd794acf0fc0450abd9de7381f129e7d&experimentKey=5d7108c24a7b4372b270a828d97cff81',\n"," 'assetId': 'cd794acf0fc0450abd9de7381f129e7d'}"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["experiment.end()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aGoU0WClHoJJ","outputId":"b5963653-8a0e-48c1-b18d-0e1f3e735202","executionInfo":{"status":"ok","timestamp":1701214736261,"user_tz":360,"elapsed":3506,"user":{"displayName":"Hern치ndez Guerrero Leonardo David","userId":"17737298581546128851"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/nicglowss/rna-densa-m2/5d7108c24a7b4372b270a828d97cff81\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     accuracy [100]                  : (0.8723333477973938, 1.0)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch_accuracy [60000]          : (0.09090909361839294, 1.0)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch_loss [60000]              : (2.9205930331954733e-06, 6.227663993835449)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epoch_duration [100]            : (15.753651162000097, 24.299163925999892)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss [100]                      : (0.0009161510388366878, 0.43367666006088257)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val_accuracy [100]              : (0.9226999878883362, 0.9822999835014343)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val_loss [100]                  : (0.06171610206365585, 0.26683875918388367)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     validate_batch_accuracy [10000] : (0.8973392248153687, 1.0)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     validate_batch_loss [10000]     : (0.004329058341681957, 0.5376294851303101)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainable_params : 623290\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Optimizer                   : SGD\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     SGD_clipnorm                : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     SGD_clipvalue               : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     SGD_ema_momentum            : 0.9\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     SGD_ema_overwrite_frequency : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     SGD_global_clipnorm         : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     SGD_is_legacy_optimizer     : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     SGD_jit_compile             : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     SGD_learning_rate           : 0.10000000149011612\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     SGD_momentum                : 0.0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     SGD_name                    : SGD\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     SGD_nesterov                : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     SGD_use_ema                 : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     SGD_weight_decay            : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch_size                  : 10\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epochs                      : 100\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss                        : categorical_crossentropy\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimizer                   : SGD\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     steps                       : 6000\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     histogram3d         : 707\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model graph         : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element       : 1 (4.78 MB)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 2\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n"]}]}]}